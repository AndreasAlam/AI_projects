{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Libraries\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import math\n",
    "\n",
    "# Import 3rd Party Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io import arff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetPath = os.getcwd() + '\\\\data\\\\1year.arff'\n",
    "conn = sqlite3.connect(os.getcwd() + '/ResultsDB.db')\n",
    "db = conn.cursor()\n",
    "db.execute('''  CREATE TABLE IF NOT EXISTS Results (Id INTEGER PRIMARY KEY, \n",
    "                Type TEXT,\n",
    "                TrainingSetPercentage REAL, \n",
    "                Epochs INTEGER, \n",
    "                LearningRate REAL,\n",
    "                Precision REAL, \n",
    "                Recall REAL, \n",
    "                Accuracy REAL, \n",
    "                F1 REAL,\n",
    "                TruePositive INTEGER,\n",
    "                TrueNegative INTEGER,\n",
    "                FalsePositive INTEGER,\n",
    "                FalseNegative INTEGER\n",
    "                )''')\n",
    "\n",
    "\n",
    "def InsertResult(Type, TrainingSetPercentage, Epochs, LearningRate, Precision, Recall, Accuracy, F1, TruePositive, TrueNegative, FalsePositive, FalseNegative):\n",
    "    db.execute(f\"   INSERT INTO Results (Type, TrainingSetPercentage, Epochs, LearningRate, Precision, Recall, Accuracy, F1, TruePositive, TrueNegative, FalsePositive, FalseNegative) VALUES('{Type}', {TrainingSetPercentage}, {Epochs}, {LearningRate}, {Precision}, {Recall}, {Accuracy}, {F1}, {TruePositive}, {TrueNegative}, {FalsePositive},  {FalseNegative})\")\n",
    "\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Initialize \n",
    "pca = custom_PCA(dataframe, k)\n",
    "#fit on the dataframe\n",
    "pca.fit()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Custom PCA\n",
    "class custom_PCA:\n",
    "    def __init__(self, A, k,  is_normalized = True):\n",
    "        self.A = A.iloc[:, :-1].to_numpy()\n",
    "        self.k = k\n",
    "        # No of rows\n",
    "        self.N_rows = A.shape[0]\n",
    "        # No of columns\n",
    "        self.N_columns = A.shape[1]\n",
    "        # Target class\n",
    "        self.target_class = A.iloc[:, -1].to_numpy().reshape(self.N_rows,1).astype(int)\n",
    "        self.is_normalized = is_normalized\n",
    "\n",
    "    def norm(self, M= ''):\n",
    "        if M=='' and self.is_normalized == False:\n",
    "            return (self.A.T - self.A.T.mean(axis = 0))/(self.A.T.max(axis=0)- self.A.T.min(axis=0))\n",
    "        elif M!='':\n",
    "            return (M - M.mean(axis = 0))/(M.max(axis=0)- M.min(axis=0))\n",
    "        else:\n",
    "            return self.A.T\n",
    " \n",
    "    \n",
    "    # Calculate the covariance matrix\n",
    "    def cov_(self):\n",
    "        A = self.norm()\n",
    "        return ((A).dot(A.T))/A.shape[0]\n",
    "\n",
    "    def generate_reduced_eigenvectors(self):\n",
    "        ''' Provide with the k-threshold and the eigenvalue/eigenvector tuple.\n",
    "            Returns the new W matrix with the reduced eigenvectors.\n",
    "        '''\n",
    "        # Initialize\n",
    "        partial_sum = 0\n",
    "        idx = 0\n",
    "        \n",
    "        e_tuple = self.list_eigenvalues()\n",
    "        \n",
    "        # Sort e_tuple by the highest eigenvalue\n",
    "        sort_eigen = sorted(e_tuple, key=lambda x: x[0], reverse = True)\n",
    "\n",
    "        ## Define how many eigenvectors to keep\n",
    "        # define the Sum of the eigenvalues\n",
    "        sum_eig = sum([pair[0] for pair in sort_eigen])\n",
    "        # Add eigenvectors as the k is smaller than the fraction\n",
    "        for ii in range(len(sort_eigen)):\n",
    "            if (partial_sum/sum_eig) <= self.k:\n",
    "                partial_sum += sort_eigen[ii][0]\n",
    "                # Index of Principal Components in the sort_eigen list\n",
    "                idx+=1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        print('Final selection is the first {} PCs'.format(idx))\n",
    "\n",
    "        # Select eigenvalues, eigenvectors\n",
    "        selected_eig = [sort_eigen[x][1] for x in range(idx) ]\n",
    "        # reshape eigenvectors\n",
    "        stack_eig = list(selected_eig[x].reshape(selected_eig[x].shape[0],1) for x in range(idx))\n",
    "        # return W\n",
    "        return np.hstack(stack_eig)\n",
    "    \n",
    "    def list_eigenvalues(self):\n",
    "        e_values, e_vector  = LA.eig(self.cov_())\n",
    "        # List of (eigenvalues, eigenvectors)\n",
    "        e_tuple = [ (np.abs(e_values[i].real), e_vector[:,i].real) for i in range(len(e_values))]\n",
    "        return e_tuple\n",
    "    \n",
    "    def fit(self):\n",
    "        # Projected Data on the N Principal Components and Normalize\n",
    "        # Should follow: (n,m) = (n,p) x (p, m)\n",
    "        data_PC_projected = self.A.dot(self.generate_reduced_eigenvectors())\n",
    "        #N Normalize\n",
    "        data_PC_projected = (data_PC_projected - data_PC_projected.mean(axis = 0))/(data_PC_projected.max(axis=0)- data_PC_projected.min(axis=0))\n",
    "        \n",
    "        # Label the new dataset\n",
    "        labeled_PC_data = np.concatenate((data_PC_projected, self.target_class), axis = 1)\n",
    "        \n",
    "        \n",
    "        print('Dimensionaly reduced matrix shape', labeled_PC_data.shape )\n",
    "        \n",
    "        # Name new columns\n",
    "        cols = ['PC_'+str(x+1) for x in range(data_PC_projected.shape[1])]\n",
    "        cols.insert(len(cols), 'Target_Class')\n",
    "\n",
    "        return pd.DataFrame(data = labeled_PC_data, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x,y,string):\n",
    "    val = -(x * np.log2(x) + y * np.log2(y))\n",
    "    print('Entropy {0}: {1:9.3f} bits'.format(string, val))\n",
    "    return val\n",
    "\n",
    "def data_balancing(df):\n",
    "    dftemp = df.where(nbcountq)[:bcount]\n",
    "    dftempb = df.where(bcountq).dropna()\n",
    "    df = pd.concat([dftemp, dftempb])\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.drop(columns=['index'],axis=1)\n",
    "    return df\n",
    "\n",
    "data,meta = arff.loadarff(DatasetPath)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.fillna(0)\n",
    "b0 = df != b'0'\n",
    "b1 = df != b'1'\n",
    "df = df.where(b0, int(0))\n",
    "df = df.where(b1, int(1))\n",
    "bcountq = df['class'] == 1\n",
    "nbcountq = df['class'] == 0\n",
    "bcount = df.where(bcountq).count()['class']\n",
    "nbcount = df.where(nbcountq).count()['class']\n",
    "# Balance of data (entropy)\n",
    "entropy(bcount / df.count()['class'], nbcount / df.count()['class'], 'before data balancing')\n",
    "df = data_balancing(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanNormalization(x):\n",
    "    return (x-np.mean(x))/(np.max(x)-np.min(x))\n",
    "# Normalize all the data (except for the class)\n",
    "dfAdjusted = meanNormalization(df.drop(df.columns[64], axis=1))\n",
    "# Add the label back to the dataset\n",
    "dfAdjusted.insert(64, \"Label\", df.iloc[:, 64], True)\n",
    "df = dfAdjusted\n",
    "dfAdjusted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCorrelationCoeffs(X, labelIndex):\n",
    "    corrList = np.array([])\n",
    "    corrResult = np.array([])\n",
    "    dfResults = np.array(X.iloc[:, labelIndex], dtype=np.int32)\n",
    "    for b in range(X.shape[1]-1):\n",
    "        print(\"{b}: {res}\".format(b = b, res=round(np.corrcoef(X.iloc[:,b], dfResults)[0][1],2)))\n",
    "        if round(np.corrcoef(X.iloc[:,b], dfResults)[0][1],2) > 0.2 or round(np.corrcoef(X.iloc[:,b], dfResults)[0][1],2) < -0.2:\n",
    "            corrResult = np.append(corrResult, {b, np.corrcoef(X.iloc[:,b], dfResults)[0][1]})\n",
    "        for a in range(b, X.shape[1]-1):\n",
    "            if round(np.corrcoef(X.iloc[:,b],X.iloc[:,a])[0][1],2) > 0.45  and b != a:\n",
    "                corrList = np.append(corrList, {b, a, round(np.corrcoef(X.iloc[:,b],X.iloc[:,a])[0][1],2)})\n",
    "    return corrList, corrResult\n",
    "# Correlation Coefficients of every feature to every feature and to the label.\n",
    "# Also returns exact correlation values for features with high correlation to label separately.\n",
    "resultC,resultR = returnCorrelationCoeffs(df, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correlation of all properties to label(bankruptcy in 5-x years)(Before data balancing (taking unequal amount of bankrupt and non-br companies))(1st year)\n",
    "0: -0.01\n",
    "1: 0.07\n",
    "2: -0.07\n",
    "3: 0.01\n",
    "4: -0.0\n",
    "5: -0.05\n",
    "6: -0.01\n",
    "7: -0.0\n",
    "8: -0.01\n",
    "9: -0.02\n",
    "10: -0.01\n",
    "11: -0.02\n",
    "12: -0.0\n",
    "13: -0.01\n",
    "14: 0.01\n",
    "15: -0.01\n",
    "16: -0.0\n",
    "17: -0.01\n",
    "18: -0.0\n",
    "19: -0.0\n",
    "20: -0.0\n",
    "21: -0.01\n",
    "22: -0.0\n",
    "23: -0.01\n",
    "24: -0.02\n",
    "25: -0.01\n",
    "26: -0.01\n",
    "27: -0.01\n",
    "28: -0.04\n",
    "29: -0.0\n",
    "30: -0.0\n",
    "31: 0.05\n",
    "32: 0.01\n",
    "33: 0.03\n",
    "34: -0.01\n",
    "35: -0.01\n",
    "36: -0.0\n",
    "37: -0.02\n",
    "38: -0.0\n",
    "39: 0.01\n",
    "40: -0.01\n",
    "41: -0.0\n",
    "42: -0.0\n",
    "43: -0.0\n",
    "44: 0.0\n",
    "45: 0.01\n",
    "46: -0.01\n",
    "47: -0.0\n",
    "48: 0.0\n",
    "49: 0.02\n",
    "50: 0.06\n",
    "51: 0.03\n",
    "52: -0.01\n",
    "53: -0.01\n",
    "54: -0.02\n",
    "55: 0.0\n",
    "56: -0.06\n",
    "57: -0.0\n",
    "58: 0.0\n",
    "59: -0.0\n",
    "60: -0.0\n",
    "61: -0.0\n",
    "62: 0.01\n",
    "63: -0.01\n",
    "\n",
    "Correlation of all properties to label(bankruptcy in 5-x years)(After data balancing (taking equal amount of bankrupt and non-br companies))(1st year)\n",
    "0: -0.03\n",
    "1: 0.05\n",
    "2: -0.05\n",
    "3: 0.02\n",
    "4: -0.05\n",
    "5: -0.05\n",
    "6: -0.08\n",
    "7: 0.01\n",
    "8: -0.04\n",
    "9: -0.06\n",
    "10: -0.14\n",
    "11: -0.1\n",
    "12: -0.07\n",
    "13: -0.08\n",
    "14: 0.05\n",
    "15: -0.09\n",
    "16: 0.01\n",
    "17: -0.08\n",
    "18: -0.07\n",
    "19: -0.03\n",
    "20: -0.21\n",
    "21: -0.14\n",
    "22: -0.07\n",
    "23: -0.05\n",
    "24: -0.06\n",
    "25: -0.09\n",
    "26: -0.04\n",
    "27: -0.01\n",
    "28: -0.16\n",
    "29: 0.05\n",
    "30: -0.07\n",
    "31: 0.04\n",
    "32: 0.04\n",
    "33: 0.07\n",
    "34: -0.15\n",
    "35: -0.03\n",
    "36: 0.02\n",
    "37: -0.06\n",
    "38: -0.11\n",
    "39: 0.06\n",
    "40: 0.02\n",
    "41: -0.1\n",
    "42: -0.04\n",
    "43: -0.04\n",
    "44: -0.01\n",
    "45: 0.03\n",
    "46: -0.09\n",
    "47: 0.02\n",
    "48: -0.07\n",
    "49: 0.02\n",
    "50: 0.05\n",
    "51: 0.04\n",
    "52: -0.05\n",
    "53: -0.05\n",
    "54: -0.14\n",
    "55: -0.21\n",
    "56: -0.04\n",
    "57: 0.09\n",
    "58: 0.03\n",
    "59: -0.03\n",
    "60: -0.04\n",
    "61: 0.05\n",
    "62: 0.02\n",
    "63: -0.05\n",
    "\n",
    "Features above .1 or below -.1 corr (year 1):\n",
    "[{-0.1413018851459517, 10} {-0.20841261923141277, 20}\n",
    " {-0.1372111718368633, 21} {-0.15799640144955474, 28}\n",
    " {-0.15073406076182475, 34} {-0.10546165292651624, 38}\n",
    " {-0.13528288570222521, 54} {-0.21264496377398492, 55}]\n",
    " \n",
    "Features above .1 or below -.1 corr (year 2):\n",
    "[{0.10991412668598526, 14} {-0.12725072730586873, 21}\n",
    " {-0.12248897923901782, 28} {-0.1234228806033094, 34}\n",
    " {-0.19772762240757855, 38} {-0.17927408959921343, 41}\n",
    " {48, -0.13396938644807177} {-0.14547197542579082, 55}]\n",
    "\n",
    "Features above .1 or below -.1 corr (year 3):\n",
    "[{-0.1364854143630141, 21} {-0.1672251455335219, 28}\n",
    " {-0.22657462686080676, 34} {-0.19712648429452306, 38}\n",
    " {-0.10521445303302412, 47} {-0.1341474257923606, 55}\n",
    " {0.16542488035357647, 60}]\n",
    " \n",
    "Features above .1 or below -.1 corr (year 4):\n",
    "[{0, -0.14524070566749694} {0.14385170130264474, 1}\n",
    " {-0.2265714657775324, 2} {-0.1140296783075827, 5}\n",
    " {-0.1498606180797063, 6} {-0.14369125535185265, 9}\n",
    " {-0.12065561697059304, 10} {-0.1498606180797063, 13}\n",
    " {-0.1498606180797063, 17} {-0.11020892718297153, 21}\n",
    " {24, -0.15866649046031725} {-0.24862248191239458, 28}\n",
    " {-0.24684802136371506, 34} {0.10606657444051945, 35}\n",
    " {-0.13293591947714103, 37} {0.20849638235992823, 50}\n",
    " {0.10830222840664715, 51} {-0.12485768761118687, 54}]\n",
    "\n",
    "Features above .1 or below -.1 corr (year 5):\n",
    "[{0.12513067718459123, 1} {-0.12372472784830899, 2}\n",
    " {8, 0.1352011982500525} {-0.47574340253390146, 20}\n",
    " {-0.35757288140112825, 28} {-0.18541429475760515, 38}\n",
    " {0.11527405099147635, 50} {-0.1859186784182609, 54}\n",
    " {-0.17713206634969345, 55} {0.14115647965635486, 57}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .89 results in 2 features which is needed to graph it\n",
    "pca = custom_PCA(df, 0.90)\n",
    "pca_df = pca.fit()\n",
    "# Custom built PCA implementation fitted to dataset\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of pca columns to label\n",
    "returnCorrelationCoeffs(pca_df, pca_df.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bankrupt companies\n",
    "pca_df_br = pca_df.where(pca_df['Target_Class'] == 1)\n",
    "\n",
    "# Non-bankrupt companies\n",
    "pca_df_non = pca_df.where(pca_df['Target_Class'] == 0)\n",
    "def plotAllFeatures(in_df_a, in_df_b):\n",
    "    for col in range(in_df_a.shape[1]-1):\n",
    "        a1 = in_df_a.iloc[:,col]\n",
    "        b1 = in_df_b.iloc[:,col]\n",
    "        for col2 in range(col, in_df_a.shape[1]-1):\n",
    "            if(col != col2):\n",
    "                a2 = in_df_a.iloc[:,col2]\n",
    "                b2 = in_df_b.iloc[:,col2]\n",
    "                plt.plot(a1, a2, 'go')\n",
    "                plt.plot(b1, b2, 'ro')\n",
    "                plt.legend(['(X)Feature {F} - (Y) Feature {S}'.format(F = col,S = col2)])\n",
    "                plt.show()\n",
    "            \n",
    "plotAllFeatures(pca_df_non, pca_df_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=13)\n",
    "pca.fit(df.drop(df.columns[64], axis=1))\n",
    "# Explained variance ratios of each feature\n",
    "print(pca.explained_variance_ratio_)\n",
    "pca_ds = pd.DataFrame(pca.transform(df.drop(df.columns[64], axis=1)))\n",
    "pca_ds.insert(pca_ds.shape[1],\"Target_Class\", pca_df['Target_Class'], True)\n",
    "# Dataset after applying PCA from Scikit-Learn\n",
    "pca_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation values of the pca of Scikit-learn\n",
    "returnCorrelationCoeffs(pca_ds, pca_ds.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Bankrupt companies\n",
    "pca_ds_br = pca_ds.where(pca_ds['Target_Class'] == 1)\n",
    "\n",
    "# Non-bankrupt companies\n",
    "pca_ds_non = pca_ds.where(pca_ds['Target_Class'] == 0)\n",
    "\n",
    "plotAllFeatures(pca_ds_non, pca_ds_br)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Standard Copy Library\n",
    "import copy\n",
    "import random\n",
    "random.seed(20)\n",
    "\n",
    "# Take a copy of the Dataset\n",
    "Dataset =  pca_df.values\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Setup Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Training Set\n",
    "TrainingSetPercentage = 0.73\n",
    "RowCount = len(Dataset)\n",
    "TrainingRows = round(RowCount * TrainingSetPercentage)\n",
    "\n",
    "# Variable Setup\n",
    "datasetCopy = copy.deepcopy(Dataset) \n",
    "TrainingSet = []\n",
    "TestingSet = []\n",
    "\n",
    "# Setup the Training Set\n",
    "for TrainingRowCounter in range(0, TrainingRows):\n",
    "    SelectedRow_Random = random.randrange(0, len(datasetCopy))\n",
    "    TrainingSet.append(datasetCopy[SelectedRow_Random])\n",
    "    # Remove so we don't choose the same one again\n",
    "    datasetCopy = np.delete(datasetCopy, SelectedRow_Random, axis=0)\n",
    "\n",
    "# For each Remaining Row, setup the Testing Set\n",
    "for x in range (len(datasetCopy)):\n",
    "    TestingSet.append(datasetCopy[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network Class\n",
    "class NeuralNetwork: \n",
    "    # Constructor\n",
    "    def __init__(self, InputNeurons, HiddenLayerNeurons):\n",
    "        # Setup Neuron Arrays\n",
    "        self.InputNeurons = np.zeros(shape=(InputNeurons, 1))\n",
    "        self.HiddenNeurons = np.random.rand(HiddenLayerNeurons, 1) # Holds the Bias\n",
    "        self.OutputNeurons = np.random.rand(1, 1)\n",
    "        # Setup Weight Arrays\n",
    "        self.WeightsInputToHidden = np.random.rand(HiddenLayerNeurons, InputNeurons)\n",
    "        self.WeightsHiddenToOutput = np.random.rand(1, HiddenLayerNeurons)\n",
    "\n",
    "    # Set the Input and Output Neurons\n",
    "    def SetInputs(self, InputArray):\n",
    "        self.InputNeurons = InputArray\n",
    "        \n",
    "    # Sigmoid Function\n",
    "    def SigmoidFunction(self, Val):\n",
    "        return (1/(1 + np.exp(-Val)))\n",
    "\n",
    "    def SquaredErrorFunction(self, Predicted, Expected):\n",
    "        return 0.5 * (math.pow(Expected - Predicted), 2)\n",
    "\n",
    "    # Train the Neural Netowrk Model\n",
    "    def Train(self, Epochs, LearningRate, ActualOutput, Verbose = False):\n",
    "        if(Verbose):\n",
    "            print(f\"Expected output is: {ActualOutput}\")\n",
    "        for epoch in range(0, Epochs):\n",
    "            # Iterate over each Hidden Layer Neuron\n",
    "            for NeuronIndex in range(0, len(self.HiddenNeurons)):\n",
    "                # Neuron = Bias + (w1 * i1h1) + (w2*i2h1) + ..\n",
    "                TempVal = 0\n",
    "                for InputNeuronIndex in range(0, len(self.InputNeurons)):\n",
    "                    TempVal += self.WeightsInputToHidden[NeuronIndex][InputNeuronIndex] * self.InputNeurons[InputNeuronIndex]\n",
    "                TempVal += self.HiddenNeurons[NeuronIndex]\n",
    "                self.HiddenNeurons[NeuronIndex] = self.SigmoidFunction(TempVal)\n",
    "\n",
    "            # Iterate over each Output Layer Neuron\n",
    "            for NeuronIndex in range(0, len(self.OutputNeurons)):\n",
    "                # Neuron = Bias + (w1 * i1h1) + (w2*i2h1) + ..\n",
    "                TempVal = 0\n",
    "                for HiddenNeuronIndex in range(0, len(self.HiddenNeurons)):\n",
    "                    TempVal += self.WeightsHiddenToOutput[NeuronIndex][HiddenNeuronIndex] * self.HiddenNeurons[HiddenNeuronIndex]\n",
    "                TempVal += self.OutputNeurons[NeuronIndex]\n",
    "                self.OutputNeurons[NeuronIndex] = self.SigmoidFunction(TempVal)\n",
    "\n",
    "            # Here we apply Mean Squared Error Cost Function, but since formula is 1/2(P-A)^2, the derivative wouldbe (P-A)\n",
    "            Error = self.OutputNeurons[0] - ActualOutput\n",
    "\n",
    "            if(Verbose):\n",
    "                print (f\"Predicted output: {self.OutputNeurons[0][0]}, Expected: {ActualOutput}..  Epoch {epoch}, Error {Error}\")\n",
    "\n",
    "            UpdatedHiddenToOutputWeights = copy.deepcopy(self.WeightsHiddenToOutput)\n",
    "            UpdatedInputToHiddenWeights = copy.deepcopy(self.WeightsInputToHidden)\n",
    "\n",
    "            # Calculate the Updated Weights from Hidden Layer to Output Layer\n",
    "            for HiddenNeuronIndex in range (0, len(self.HiddenNeurons)):\n",
    "                UpdatedHiddenToOutputWeights[0][HiddenNeuronIndex] -= (LearningRate * ((Error) * (self.HiddenNeurons[HiddenNeuronIndex])))\n",
    "            \n",
    "            # Calculate the Updated Weights from Input Layer to Hidden Layer\n",
    "            for HiddenNeuronIndex in range (0, len(self.HiddenNeurons)):\n",
    "                for InputNeuronIndex in range (0, len(self.InputNeurons)):\n",
    "                    UpdatedInputToHiddenWeights[HiddenNeuronIndex][InputNeuronIndex] -= (LearningRate * (self.InputNeurons[InputNeuronIndex] * ((Error) * self.WeightsHiddenToOutput[0][HiddenNeuronIndex])))\n",
    "            \n",
    "            # Update the weights\n",
    "            self.WeightsInputToHidden = copy.deepcopy(UpdatedInputToHiddenWeights)\n",
    "            self.WeightsHiddenToOutput = copy.deepcopy(UpdatedHiddenToOutputWeights)\n",
    "            \n",
    "            \n",
    "    # Function to Predict on a trained NN\n",
    "    def Predict(self, ExpectedOutput):\n",
    "        # Do Forward Propagation on current weights\n",
    "        # Iterate over each Hidden Layer Neuron\n",
    "        for NeuronIndex in range(0, len(self.HiddenNeurons)):\n",
    "            # Neuron = Bias + (w1 * i1h1) + (w2*i2h1) + ..\n",
    "            TempVal = 0\n",
    "            for InputNeuronIndex in range(0, len(self.InputNeurons)):\n",
    "                TempVal += self.WeightsInputToHidden[NeuronIndex][InputNeuronIndex] * self.InputNeurons[InputNeuronIndex]\n",
    "            TempVal += self.HiddenNeurons[NeuronIndex]\n",
    "            self.HiddenNeurons[NeuronIndex] = self.SigmoidFunction(TempVal)\n",
    "\n",
    "        # Iterate over each Output Layer Neuron\n",
    "        for NeuronIndex in range(0, len(self.OutputNeurons)):\n",
    "            # Neuron = Bias + (w1 * i1h1) + (w2*i2h1) + ..\n",
    "            TempVal = 0\n",
    "            for HiddenNeuronIndex in range(0, len(self.HiddenNeurons)):\n",
    "                TempVal += self.WeightsHiddenToOutput[NeuronIndex][HiddenNeuronIndex] * self.HiddenNeurons[HiddenNeuronIndex]\n",
    "            TempVal += self.OutputNeurons[NeuronIndex]\n",
    "            self.OutputNeurons[NeuronIndex] = self.SigmoidFunction(TempVal)\n",
    "\n",
    "        Prediction = round(self.OutputNeurons[0][0])\n",
    "        print (f\"Predicted: {Prediction}, Expected: {ExpectedOutput}\")\n",
    "        return Prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Do Processing and Print Metric Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_rows, num_cols = Dataset.shape\n",
    "Epochs = 15000\n",
    "LearningRate = 0.01\n",
    "\n",
    "TruePositive = 0\n",
    "FalsePositive = 0\n",
    "FalseNegative = 0\n",
    "TrueNegative = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit Learn Neural Network\n",
    "SciKitTrainingSet = copy.deepcopy(TrainingSet)\n",
    "SciKitTrainingSetClassifications = copy.deepcopy(TrainingSet)\n",
    "\n",
    "SciKitTrainingSet = np.delete(SciKitTrainingSet, -1, axis=1)\n",
    "SciKitTrainingSetClassifications = np.ravel(np.delete(SciKitTrainingSetClassifications, np.s_[0:num_cols-1] , axis=1))\n",
    "\n",
    "SciKitTestingSet = copy.deepcopy(TestingSet)\n",
    "SciKitTestingSetClassifications = copy.deepcopy(TestingSet)\n",
    "\n",
    "SciKitTestingSet = np.delete(SciKitTestingSet, -1, axis=1)\n",
    "SciKitTestingSetClassifications = np.ravel(np.delete(SciKitTestingSetClassifications, np.s_[0:num_cols-1], axis=1))\n",
    "\n",
    "SciKitNN = MLPClassifier(solver=\"sgd\", activation=\"logistic\", hidden_layer_sizes=(1, math.ceil((num_cols+1)/2)), learning_rate=\"constant\", learning_rate_init=LearningRate, max_iter=Epochs, random_state=1)\n",
    "SciKitNN.fit(SciKitTrainingSet, SciKitTrainingSetClassifications)\n",
    "SciKitNNPrediction = SciKitNN.predict(SciKitTestingSet)\n",
    "SciKitNNScore = accuracy_score(SciKitTestingSetClassifications, SciKitNNPrediction)\n",
    "print(f\"SciKit Accuracy: {SciKitNNScore}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Constructor Parameters: InputLayer Neurons, HiddenLayer Neurons.. Output here is always 1 Neuron 1 or 0\n",
    "NN = NeuralNetwork(num_cols-1, math.ceil((num_cols+1)/2))\n",
    "print(f\"Starting Training Epochs: {Epochs}, LearningRate: {LearningRate}\")\n",
    "for Index, TrSetRow in enumerate(TrainingSet):\n",
    "    print(f\"Training: {Index+1} of {len(TrainingSet)}\")\n",
    "    NN.SetInputs(TrSetRow[0:num_cols-1])\n",
    "    # Parameters for NN Train: Epochs (iterations for training), Learning Rate, Actual Output\n",
    "    NN.Train(Epochs, LearningRate, TrSetRow[num_cols-1], Verbose=False)\n",
    "\n",
    "print(\"Starting Testing\")\n",
    "\n",
    "for TestSetRow in TestingSet:\n",
    "    NN.SetInputs(TestSetRow[0:num_cols-1])\n",
    "    # Parameters for NN Train: Epochs (iterations for training), Learning Rate, Actual Output\n",
    "    Prediction = NN.Predict(TestSetRow[num_cols-1])\n",
    "\n",
    "    # Update Metrics\n",
    "    if(TestSetRow[num_cols-1] == 1 and Prediction == 1):\n",
    "        TruePositive += 1\n",
    "    elif (TestSetRow[num_cols-1] == 1 and Prediction == 0):\n",
    "        FalseNegative += 1\n",
    "    elif (TestSetRow[num_cols-1] == 0 and Prediction == 1):\n",
    "        FalsePositive += 1\n",
    "    elif (TestSetRow[num_cols-1] == 0 and Prediction == 0):\n",
    "        TrueNegative += 1\n",
    "\n",
    "# Precision: TP/ (TP+FP)\n",
    "Precision = TruePositive / (TruePositive + FalsePositive)\n",
    "# Recall: TP / (TP+FN)\n",
    "Recall = TruePositive / (TruePositive + FalseNegative)\n",
    "# Accuracy: (TP + TN)/(TP + TN + FP + FN)\n",
    "Accuracy = (TruePositive + TrueNegative) / (TruePositive + TrueNegative + FalsePositive + FalseNegative)\n",
    "# F1 Score: (2 * Precision * Recall) / (Precision + Recall)\n",
    "F1 = (2 * Precision * Recall)/(Precision + Recall)\n",
    "print(f\"True Positives: {TruePositive}\")\n",
    "print(f\"True Negatives: {TrueNegative}\")\n",
    "print(f\"False Positives: {FalsePositive}\")\n",
    "print(f\"False Negatives: {FalseNegative}\")\n",
    "\n",
    "print(f\"Precision {Precision}\")\n",
    "print(f\"Recall {Recall}\")\n",
    "print(f\"Accuracy {Accuracy}\")\n",
    "print(f\"F1 Score {F1}\")\n",
    "\n",
    "# Insert Results to DB for Plotting\n",
    "InsertResult(\"Neural Network\", TrainingSetPercentage, Epochs, LearningRate, Precision, Recall, Accuracy, F1, TruePositive, TrueNegative, FalsePositive, FalseNegative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Confusion Matrix\n",
    "def confusion_matrix_visualization(confusion_matrix):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(confusion_matrix, cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(confusion_matrix.shape[1]),\n",
    "           yticks=np.arange(confusion_matrix.shape[0]),\n",
    "           xticklabels=['Bankrupted', 'Saved'],  \n",
    "           yticklabels=['GT_Bankrupted', 'GT_Saved'],\n",
    "           title = 'Confusion Matrix' )\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            ax.text(j, i, confusion_matrix[i, j], size = 18, horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_matrix = np.asarray([[TruePositive, FalsePositive], [FalseNegative,TrueNegative]])\n",
    "confusion_matrix_visualization(confusion_matrix = confusion_matrix)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate labels from variables\n",
    "X_var = np.asarray(TrainingSet)[:, :-1]\n",
    "Y_var = np.asarray(TrainingSet)[:, -1]\n",
    "\n",
    "# Put the Test set in a df\n",
    "TestData_df = pd.DataFrame(data = TestingSet, columns = pca_df.columns)\n",
    "TestData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "a = 0.1\n",
    "# Iterations number\n",
    "no_of_iter = 3000000\n",
    "\n",
    "# Initialize Weights\n",
    "W = np.random.uniform(low=-0.1, high=0.1, size=(X_var.shape[1]))\n",
    "\n",
    "N = X_var.shape[0]\n",
    "\n",
    "x_w=X_var.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Function\n",
    "def Sigmoid_F(x_var, w):\n",
    "    x_w = np.dot(x_var, w)\n",
    "    return 1 / (1 + np.exp(-x_w))\n",
    "\n",
    "def Loss(Y_var, sig_Y):\n",
    "    return (-(Y_var*np.log(sig_Y)) -  ((1 - Y_var) * np.log(1 - sig_Y))).mean()\n",
    "\n",
    "def Loss_derivative(sig_y, truth_y, x_matrix, N=N):\n",
    "    dY =  sig_y - truth_y \n",
    "    return np.dot(dY, x_matrix)/N\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "for ii in range(no_of_iter):   \n",
    "    # Sigmoid function output\n",
    "    sig_Y = Sigmoid_F(X_var, W)\n",
    "    # Loss Function\n",
    "    L = Loss(Y_var, sig_Y)\n",
    "    # Gradient computation\n",
    "    dw = Loss_derivative(sig_y = sig_Y, truth_y = Y_var, x_matrix = X_var)\n",
    "    # Update weights\n",
    "    W = W - a * dw\n",
    "\n",
    "    \n",
    "print('Final Loss: ', L)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom LR model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =pd.DataFrame(columns = ['Index', 'bankruptcy', 'Ground_Truth'])\n",
    "\n",
    "# Loop over the test set\n",
    "for index, row in TestData_df.iloc[:, :-1].iterrows():\n",
    "\n",
    "    prob = Sigmoid_F(row.tolist(), W)    \n",
    "    if prob> 0.5:\n",
    "        predictions = predictions.append({'Index':index, 'bankruptcy': 1, 'Ground_Truth': TestData_df.iloc[index, -1]  }, ignore_index=True )\n",
    "    elif prob <= 0.5:\n",
    "        predictions = predictions.append({'Index':index, 'bankruptcy': 0, 'Ground_Truth': TestData_df.iloc[index, -1]  }, ignore_index=True )\n",
    "        \n",
    "\n",
    "# Metrics\n",
    "TP = predictions.loc[(predictions.bankruptcy == 1) & (predictions.Ground_Truth == 1)].shape[0]\n",
    "TN = predictions.loc[(predictions.bankruptcy == 0) & (predictions.Ground_Truth == 0)].shape[0]\n",
    "FP = predictions.loc[(predictions.bankruptcy == 1) & (predictions.Ground_Truth == 0)].shape[0]\n",
    "FN = predictions.loc[(predictions.bankruptcy == 0) & (predictions.Ground_Truth == 1)].shape[0]\n",
    "\n",
    "# Confusion Matrix\n",
    "confusion_matrix = np.asarray([[TP, FP], [FN,TN]])\n",
    "\n",
    "metrics_string = 'True Positives {}  True Negatives {}  False Positives {}  False Negatives {}'\n",
    "print(metrics_string.format(TP, TN, FP, FN))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Confusion Matrix\n",
    "def confusion_matrix_visualization(confusion_matrix):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(confusion_matrix, cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(confusion_matrix.shape[1]),\n",
    "           yticks=np.arange(confusion_matrix.shape[0]),\n",
    "           xticklabels=['Bankrupted', 'Saved'],  \n",
    "           yticklabels=['GT_Bankrupted', 'GT_Saved'],\n",
    "           title = 'Confusion Matrix' )\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        for j in range(confusion_matrix.shape[1]):\n",
    "            ax.text(j, i, confusion_matrix[i, j], size = 18, horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "confusion_matrix_visualization(confusion_matrix = confusion_matrix)\n",
    "\n",
    "# Precision\n",
    "Precision = TP/(TP + FP)\n",
    "# Recall\n",
    "Recall = TP/(TP + FN)\n",
    "# Accuracy\n",
    "Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "#F1 Score\n",
    "F_1 = 2*(Precision*Recall)/(Precision+Recall)\n",
    "\n",
    "print('Precision {} \\nRecall {} \\nAccuracy {} \\nF1 score {}'.format(Precision, Recall, Accuracy,  F_1 ))\n",
    "InsertResult(\"Logistic Regression\", TrainingSetPercentage, no_of_iter, a, Precision, Recall, Accuracy, F_1, TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "no_of_iter = 1000000\n",
    "a = 0\n",
    "logisticRegr = LogisticRegression(max_iter = no_of_iter)\n",
    "logisticRegr.fit(X_var, Y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Target class from the \n",
    "Y_test = np.array(TestingSet)[:, -1]\n",
    "X_test = np.array(TestingSet)[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_precision_score = precision_score(Y_test, predictions )\n",
    "skl_recall_score = recall_score(Y_test, predictions )\n",
    "skl_accuracy_score = accuracy_score(Y_test, predictions )\n",
    "skl_f1_score = f1_score(Y_test, predictions )\n",
    "\n",
    "print(type(skl_f1_score))\n",
    "TN, FP, FN, TP = confusion_matrix(Y_test.tolist(), predictions.tolist()).ravel()\n",
    "\n",
    "print(\"Precision {} \\nRecall {} \\nAccuracy {} \\nF1 score {}\".format(float(skl_precision_score), float(skl_recall_score), float(skl_accuracy_score), float(skl_f1_score)))\n",
    "InsertResult(\"SkLearn_Logistic_Regression\", TrainingSetPercentage, no_of_iter, a, skl_precision_score, skl_recall_score, skl_accuracy_score, skl_f1_score, TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results csv, obtained from db\n",
    "results = pd.read_csv(os.getcwd() + '\\\\Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Epochs', 'Precision', 'Recall', 'Accuracy', 'F1', ]\n",
    "\n",
    "# precision\n",
    "for iter in range (0, 2):\n",
    "    if (iter == 0):\n",
    "        Pr_a1 = results[cols].loc[(results.LearningRate==0.1) & (results.Type == 'Logistic Regression')]\n",
    "        Pr_a2 = results[cols].loc[(results.LearningRate==0.01) & (results.Type == 'Logistic Regression')]\n",
    "        Pr_a3 = results[cols].loc[(results.LearningRate==0.001) & (results.Type == 'Logistic Regression')]\n",
    "        \n",
    "    elif (iter == 1):\n",
    "        Pr_a1 = results[cols].loc[(results.LearningRate==0.1) & (results.Type == 'Neural Network')]\n",
    "        Pr_a2 = results[cols].loc[(results.LearningRate==0.01) & (results.Type == 'Neural Network')]\n",
    "        Pr_a3 = results[cols].loc[(results.LearningRate==0.001) & (results.Type == 'Neural Network')]\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize= (10,10))#, sharey = 'row')\n",
    "\n",
    "    #Precision\n",
    "    ax1.plot(Pr_a1.Epochs, Pr_a1.Precision, 'o--')\n",
    "    ax1.plot(Pr_a2.Epochs, Pr_a2.Precision, 'x--')\n",
    "    ax1.plot(Pr_a3.Epochs, Pr_a3.Precision, '^--')\n",
    "    ax1.set_xlabel('Training Iterations')\n",
    "    ax1.set_ylabel('Precision %')\n",
    "    ax1.legend(['a1=0.1', 'a2=0.01', 'a3=0.001'], loc='upper right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Recall\n",
    "    ax2.plot(Pr_a1.Epochs, Pr_a1.Recall, 'o--')\n",
    "    ax2.plot(Pr_a2.Epochs, Pr_a2.Recall, 'x--')\n",
    "    ax2.plot(Pr_a3.Epochs, Pr_a3.Recall, '^--')\n",
    "    ax2.set_xlabel('Training Iterations')\n",
    "    ax2.set_ylabel('Recall %')\n",
    "    ax2.legend(['a1=0.1', 'a2=0.01', 'a3=0.001'], loc='upper right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Accuracy\n",
    "    ax3.plot(Pr_a1.Epochs, Pr_a1.Accuracy, 'o--')\n",
    "    ax3.plot(Pr_a2.Epochs, Pr_a2.Accuracy, 'x--')\n",
    "    ax3.plot(Pr_a3.Epochs, Pr_a3.Accuracy, '^--')\n",
    "    ax3.set_xlabel('Training Iterations')\n",
    "    ax3.set_ylabel('Accuracy %')\n",
    "    ax3.legend(['a1=0.1', 'a2=0.01', 'a3=0.001'], loc='upper right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    # F1\n",
    "    ax4.plot(Pr_a1.Epochs, Pr_a1.F1, 'o--')\n",
    "    ax4.plot(Pr_a2.Epochs, Pr_a2.F1, 'x--')\n",
    "    ax4.plot(Pr_a3.Epochs, Pr_a3.F1, '^--')\n",
    "    ax4.set_xlabel('Training Iterations')\n",
    "    ax4.set_ylabel('F1 score %')\n",
    "    ax4.legend(['a1=0.1', 'a2=0.01', 'a3=0.001'], loc='upper right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sklearn Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn results\n",
    "Pr_skl = results[cols].loc[results.Type == 'SkLearn_Logistic_Regression']\n",
    "Pr_skl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize= (10,10))#, sharey = 'row')\n",
    "\n",
    "#Precision\n",
    "ax1.plot(Pr_skl.Epochs, Pr_skl.Precision, 'o--')\n",
    "ax1.set_xlabel('Training Iterations')\n",
    "ax1.set_ylabel('Precision %')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Recall\n",
    "ax2.plot(Pr_skl.Epochs, Pr_skl.Recall, 'o--')\n",
    "ax2.set_xlabel('Training Iterations')\n",
    "ax2.set_ylabel('Recall %')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Accuracy\n",
    "ax3.plot(Pr_skl.Epochs, Pr_skl.Accuracy, 'o--')\n",
    "ax3.set_xlabel('Training Iterations')\n",
    "ax3.set_ylabel('Accuracy %')\n",
    "plt.tight_layout()\n",
    "\n",
    "# F1\n",
    "ax4.plot(Pr_skl.Epochs, Pr_skl.F1, 'o--')\n",
    "ax4.set_xlabel('Training Iterations')\n",
    "ax4.set_ylabel('F1 score %')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}